{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# South Park data Set analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Opening the .csv file\n",
    "\"\"\"\n",
    "different_files = ['All-seasons-south-park.csv']\n",
    "search_terms = []\n",
    "with open(different_files[0], encoding='utf-8') as csv_file:\n",
    "    csv_file.readline()\n",
    "    for line in csv_file:\n",
    "        \n",
    "        line_contents = line.split(',')\n",
    "        for word in line_contents:\n",
    "            if word != '\"\\n':\n",
    "                search_terms.append(word)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is this dataset?\n",
    "\n",
    "### This .csv file contains script information including: season, episode, character, & line from many, many south park episodes\n",
    "\n",
    "### Hypotheses:\n",
    "#### Since this file is smaller than the search terms csv file I believe that the runtime will be faster than the frequency analysis of the search terms file. This means that it should be able to do the analysis in under 10 microseconds. Since 10 microseconds is already really fast, it might be the same time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All Information</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"You guys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you guys! Chef is going away. \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     All Information\n",
       "0                                 10\n",
       "1                                  1\n",
       "2                               Stan\n",
       "3                          \"You guys\n",
       "4   you guys! Chef is going away. \\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "south_park_df = pd.DataFrame(search_terms, columns=['All Information'])\n",
    "south_park_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning function and cleaning of pandas data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_token(token):\n",
    "    token = re.sub('\\'', '', token)\n",
    "    token = re.sub('\\n', '', token)\n",
    "    token = re.sub('\\\"', '', token)\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All Information</th>\n",
       "      <th>Cleaned Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stan</td>\n",
       "      <td>Stan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"You guys</td>\n",
       "      <td>You guys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you guys! Chef is going away. \\n</td>\n",
       "      <td>you guys! Chef is going away.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kyle</td>\n",
       "      <td>Kyle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"Going away? For how long?\\n</td>\n",
       "      <td>Going away? For how long?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Stan</td>\n",
       "      <td>Stan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\"Forever.\\n</td>\n",
       "      <td>Forever.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Chef</td>\n",
       "      <td>Chef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\"I'm sorry boys.\\n</td>\n",
       "      <td>Im sorry boys.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Stan</td>\n",
       "      <td>Stan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      All Information                   Cleaned Tokens\n",
       "0                                  10                               10\n",
       "1                                   1                                1\n",
       "2                                Stan                             Stan\n",
       "3                           \"You guys                         You guys\n",
       "4    you guys! Chef is going away. \\n   you guys! Chef is going away. \n",
       "5                                  10                               10\n",
       "6                                   1                                1\n",
       "7                                Kyle                             Kyle\n",
       "8        \"Going away? For how long?\\n        Going away? For how long?\n",
       "9                                  10                               10\n",
       "10                                  1                                1\n",
       "11                               Stan                             Stan\n",
       "12                        \"Forever.\\n                         Forever.\n",
       "13                                 10                               10\n",
       "14                                  1                                1\n",
       "15                               Chef                             Chef\n",
       "16                 \"I'm sorry boys.\\n                   Im sorry boys.\n",
       "17                                 10                               10\n",
       "18                                  1                                1\n",
       "19                               Stan                             Stan"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "south_park_df['Cleaned Tokens'] = south_park_df['All Information'].apply(clean_token)\n",
    "south_park_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency analysis methods and sorting the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_dict(search_terms):\n",
    "    \"\"\"\n",
    "    Parameter: list of searchterms\n",
    "    Return: Dictionary frequency number of words\n",
    "    Return key: words\n",
    "    Return values: number of times in list\n",
    "    \"\"\"\n",
    "    seen = set()\n",
    "    frequency_search_terms = {}\n",
    "    for i in range(len(search_terms)):\n",
    "        if search_terms[i] in seen:\n",
    "            frequency_search_terms[search_terms[i]] += 1\n",
    "        else:\n",
    "            frequency_search_terms[search_terms[i]] = 1\n",
    "            seen.add(search_terms[i])\n",
    "    \n",
    "    return frequency_search_terms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorting_the_dict(frequency_dict):\n",
    "    \"\"\"\n",
    "    Sorts dictionary by values from high to low\n",
    "    Param: Dictionary with number values\n",
    "    Return: Sorted Dictionary values from high to low\n",
    "    \"\"\"\n",
    "    sorted_dict = {}\n",
    "    marklist = sorted(frequency_dict.items(), key=lambda x:x[1], reverse=True)\n",
    "    sort_dict = dict(marklist)\n",
    "    return sort_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runtime anmalysis of frequency_dict method and value_counts method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 4.53 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "frequency_dictionary = frequency_dict(search_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1 µs, sys: 0 ns, total: 1 µs\n",
      "Wall time: 3.34 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "sorted_dict = sorting_the_dict(frequency_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1e+03 ns, sys: 0 ns, total: 1e+03 ns\n",
      "Wall time: 2.86 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2                                                                                                                       11187\n",
       "4                                                                                                                       10783\n",
       "3                                                                                                                       10515\n",
       "6                                                                                                                        9945\n",
       "Cartman                                                                                                                  9912\n",
       "                                                                                                                        ...  \n",
       "Kennys parents must be laughing pretty hard about now! Were dumb enough to believe Kennys body could be in a teapot!        1\n",
       " that is- that is the most beautiful thing I have ever heard.                                                               1\n",
       " dude. She came in second.                                                                                                  1\n",
       " its not like its vulgar or violent.                                                                                        1\n",
       " were just now starting to see people get really pissed off at each other.                                                  1\n",
       "Name: Cleaned Tokens, Length: 101571, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "south_park_df['Cleaned Tokens'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in sorted_dict:\n",
    "    #print(f'Key: {key},       Value: {sorted_dict[key]}')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions:\n",
    "### The cell runtimes were consistently around 5 microseconds, which is in line with what my hypothesis predicted. The difference between 5 microseconds and 10 microseconds is so little that the difference can be attributed to many outside factors. Another thing that can be noted is that the runtimes between value_counts from pandas and the frequency counter method were similar once again. \n",
    "### The hypothesis lines up with the outcomes of the tests I ran.\n",
    "\n",
    "### One thing that can be said is that the method I made and the pandas value_counts method are very fast, both can complete this analysis in almost no time. \n",
    "\n",
    "# Some interesting facts that can be taken from the analysis:\n",
    "\n",
    "### Who has the most lines:\n",
    "\n",
    "#### 1. Cartman\n",
    "#### 2. Stan\n",
    "#### 3. Kyle\n",
    "#### 4. Butters\n",
    "#### 5. Randy\n",
    "\n",
    "### What are the most common lines:\n",
    "\n",
    "#### 1. 'Oh'\n",
    "#### 2. 'Well'\n",
    "#### 3. 'Yeah'\n",
    "#### 4. 'No'\n",
    "#### 5. 'Dude'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
