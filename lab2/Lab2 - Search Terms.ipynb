{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2 - Search terms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in the data into a list called search_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing first 100 search terms to see what it looks like:\n",
      " ['36969', 'CMED 500100', 'KEND 5750', 'CMED 980228', 'DYNC1815H', 'DYND70642', 'DEES KC-21400', 'LINK PC1000', '7081714', 'KEND 8507SA', 'KEND 8881-892910', 'bacon', 'pineapple', '5065265', 'enfit70550', 'cheese cheddar', '68010', '55507', '8116055', '2366607', 'buttermilk', '3009697', '4185775', '1953358', '2157315', '4782694', '6653558', '7062615', 'milk', 'chicken breast', 'DRIT 0028', '4944450', 'romain', 'banana', '16sl', 'URO51211CH', 'HUDS 00640', 'bacon', '7024755', '6056105', '6928832', 'name%20tags', '3029404', 'cut fruit', 'HUDS 003-40', 'milk', '4828182', '1448950', 'biscuit', '101460', '269110', '4549099', '5 way', '260119', '314828', '888340', '241571', 'milk', '101420', '272180', '596060', '4019139', 'GERI HCS4485', 'bacon', 'mash', 'liquid egg', '3602786', '1009711', 'wipes', 'DYND11756H', 'bacon', '4252104', '874302', '4066353', 'creamer', '3778925', '2105850', '3602976', '4908299', 'HUDS 1885', 'lettuce', 'apple sauce', '61390', 'cottage', '169897', '55535', 'milk', '504602', '7551324', '6374817', 'lactose milk', '1132050', '358608', '1158542', 'JUICE ORG', 'milk', 'biscuit', 'creamer', '373640', '1158542']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Opening the .csv file\n",
    "\"\"\"\n",
    "different_files = ['searchTerms.csv', '10xFileReal.csv', '100xFile.csv']\n",
    "search_terms = []\n",
    "with open(different_files[0], encoding='utf-8') as csv_file:\n",
    "    csv_file.readline()\n",
    "    for line in csv_file:\n",
    "        \n",
    "        line_contents = line.split(',')\n",
    "        \n",
    "        search_terms.append(line_contents[0])\n",
    "    print(f'Printing first 100 search terms to see what it looks like:\\n {search_terms[0:100]}')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning token function (removing '%20' from all Strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_token(token):\n",
    "    \"\"\"\n",
    "    Replace '%20' with a \" \"\n",
    "    Param: dirty token with '%20'\n",
    "    Return: Clean token without \"%20\"\n",
    "    \"\"\"\n",
    "    token = token.replace('%20', ' ')\n",
    "    return token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning token function (removing spaces from tokens and making new list with seperate tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I'm sorry, but passing in a list makes way more sense to me than passing in individual tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_spaces2(search_terms):\n",
    "    \"\"\"\n",
    "    The new and improved function that doesn't care about memory,\n",
    "    because it is cool\n",
    "    \"\"\"\n",
    "    space = ' '\n",
    "    new_search_terms = []\n",
    "    for i in range(len(search_terms)):\n",
    "        if space in search_terms[i]:\n",
    "            terms = search_terms[i].split(' ')\n",
    "            for term in terms:\n",
    "                new_search_terms.append(term)\n",
    "        else:\n",
    "            new_search_terms.append(search_terms[i])\n",
    "    return new_search_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_numbers_and_punct(search_terms):\n",
    "    \"\"\"\n",
    "    removes number and punctuation\n",
    "    param: list of search terms\n",
    "    return: list without numbers and punctuation\n",
    "    \"\"\"\n",
    "    new_list = []\n",
    "    for i in range(len(search_terms)):\n",
    "        no_numbers = re.sub(r'[0-9]+', '', search_terms[i])\n",
    "        no_punct = re.sub(r'[^\\w\\s]', '', no_numbers)\n",
    "        if no_punct != '':\n",
    "            new_list.append(no_punct)\n",
    "        \n",
    "\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the tokens (getting rid of spaces, numbers and punctuation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bad = '%20'\n",
    "for i in range(len(search_terms)):\n",
    "    search_terms[i] = search_terms[i].lower()\n",
    "    if bad in search_terms[i]:\n",
    "        search_terms[i] = clean_token(search_terms[i])\n",
    "        \n",
    "search_terms = remove_spaces2(search_terms)\n",
    "search_terms = remove_numbers_and_punct(search_terms)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Keys: word        Values: number of times word appears\n",
    " \n",
    "### Turning list into dictionary with number of times a word appears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_dict(search_terms):\n",
    "    \"\"\"\n",
    "    Parameter: list of searchterms\n",
    "    Return: Dictionary frequency number of words\n",
    "    Return key: words\n",
    "    Return values: number of times in list\n",
    "    \"\"\"\n",
    "    seen = set()\n",
    "    frequency_search_terms = {}\n",
    "    for i in range(len(search_terms)):\n",
    "        if search_terms[i] in seen:\n",
    "            frequency_search_terms[search_terms[i]] += 1\n",
    "        else:\n",
    "            frequency_search_terms[search_terms[i]] = 1\n",
    "            seen.add(search_terms[i])\n",
    "    \n",
    "    return frequency_search_terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary sorting function Values from high to low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorting_the_dict(frequency_dict):\n",
    "    \"\"\"\n",
    "    Sorts dictionary by values from high to low\n",
    "    Param: Dictionary with number values\n",
    "    Return: Sorted Dictionary values from high to low\n",
    "    \"\"\"\n",
    "    sorted_dict = {}\n",
    "    marklist = sorted(frequency_dict.items(), key=lambda x:x[1], reverse=True)\n",
    "    sort_dict = dict(marklist)\n",
    "    return sort_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally sorting the dictionary using the preceding methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_search_terms = frequency_dict(search_terms)\n",
    "sorted_dict = sorting_the_dict(frequency_search_terms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorted dictionary is called sorted_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a dictionary with incorrect spelling as keys and correct spelling as value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.78 s, sys: 351 ms, total: 3.13 s\n",
      "Wall time: 2.94 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from spellchecker import SpellChecker\n",
    "import pattern.en\n",
    "def spell_check_dictionary(sorted_dict):  \n",
    "    \"\"\"\n",
    "    Making the spell check dictionary\n",
    "    Param: a dictionary to start with misspelled keys\n",
    "    return spell check dictionary  \n",
    "    key(misspelled word) \n",
    "    value(correct word)\n",
    "    \"\"\"\n",
    "    spell_check_dict = {}\n",
    "    spell = SpellChecker(language='en', distance=1)\n",
    "    #Distance if it is more than one than it doesn't finish in under 10 minutes\n",
    "    #I get bored and cancel it\n",
    "    # find those words that may be misspelled\n",
    "    misspelled = spell.unknown(sorted_dict.keys())\n",
    "    print(len(misspelled))\n",
    "\n",
    "    for word in misspelled:\n",
    "        if word is not spell.correction(word):\n",
    "            spell_check_dict[word] = spell.correction(word)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return spell_check_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the slowest cell. If direction is one it completes pretty fast, however it is more than 1 it starts to take a very very long time.\n",
    "When direction is 1, the spell checker is only allowed to change one letter in the word to make a valid word.\n",
    "so that is it needs to try 25 different letters (not incl. one that is aldready there) for each letter in the original word\n",
    "so if a word is three letters long, it needs to try 25 letters on the first letter, 25 on the second and 25 on the third for a total of 75.\n",
    "When the direction is 2, the spell checker can change two letters in a word to make a valid one. \n",
    "So that means it can try 25 different letters and then another 25 on the next or the next letter. So it needs to check:\n",
    "total_times = 25 * 25 + 25 * 25 + 25 * 25 for a 3 letter word\n",
    "So one direction total times for a 3 letter word is 75 while two directions is 1875\n",
    "\n",
    "3 letter word represented as tuple = (1, 2, 3)\n",
    "possible combinations: (1,2), (1,3), (2,3)\n",
    "Total combinations: 3\n",
    "\n",
    "This gets even worse the more letters there are in the word.\n",
    "\n",
    "This comparison resembles something where one direction is n for each letter and two directions is n^2 for each pair of letters\n",
    "\n",
    "4 letter word represented as tuple = (1, 2, 3, 4)\n",
    "possible combinations: (1,2), (1,3), (1,4), (2,3), (2,4), (3,4)\n",
    "Total combinations: 6\n",
    "Total times for one direction (4 letter word): 100\n",
    "Total times for 2 directions (4 letter word): 3750\n",
    "\n",
    "5letter word represented as tuple = (1, 2, 3, 4, 5)\n",
    "possible combinations: (1,2), (1,3), (1,4), (1,5), (2,3), (2,4), (2,5), (3,4), (3,5), (4,5)\n",
    "Total combinations: 10\n",
    "Total times for one direction (5 letter word):125\n",
    "Total times for 2 directions (5 letter word): 6250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7013\n"
     ]
    }
   ],
   "source": [
    "spell_check_dict = spell_check_dictionary(sorted_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparing_spellcheck_dict(sorted_dict):\n",
    "    \"\"\"\n",
    "    Fixing the dictionary and attributing wrong spelling values \n",
    "    to correct ones\n",
    "    param: sorted dictionary\n",
    "    return: correct dictionary without misspellings\n",
    "    \"\"\"\n",
    "    correct_token = ''\n",
    "    bad_keys = []\n",
    "    for key in sorted_dict:\n",
    "        if key in spell_check_dict:\n",
    "            \n",
    "            correct_token = spell_check_dict[key]\n",
    "            value = sorted_dict[key]\n",
    "            if correct_token in sorted_dict:\n",
    "                sorted_dict[correct_token] += value\n",
    "                bad_keys.append(key)\n",
    "            \n",
    "                \n",
    "    \n",
    "    for key in bad_keys:\n",
    "        sorted_dict.pop(key)\n",
    "    return sorted_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10812\n"
     ]
    }
   ],
   "source": [
    "sorted_dict = comparing_spellcheck_dict(sorted_dict)\n",
    "sorted_dict = sorting_the_dict(sorted_dict)\n",
    "print(len(sorted_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def write_to_csv_file(filename, dictionary):\n",
    "    \"\"\"\n",
    "    Write to csv file\n",
    "    Param: file name and a dictionary to write\n",
    "    \"\"\"\n",
    "\n",
    "    with open(f'{filename}.csv', 'w') as f:\n",
    "        for key in dictionary.keys():\n",
    "            f.write(f'{key}, {dictionary[key]},\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_csv_file('test1kp', sorted_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Question:\n",
    "\n",
    "BONUS 5% available for generating files of these sizes and re-running the analysis to confirm your estimations (documented appropriately, but no need to include your files)\n",
    "\n",
    "Total time regular file: 3.17 seconds\n",
    "\n",
    "Total time 10x file:     3.22 seconds\n",
    "\n",
    "Total time 100x file:    3.7 seconds\n",
    "\n",
    "As one can see, the times don't change very much. That is because the files created simply copied themselves and didn't change the values of each search. If different search results were taken that had different values, the spellchecker would have taken longer to process, but since it was the same misspelled words as last time it took about as long."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
