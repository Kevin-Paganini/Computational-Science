{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5 Sparse Spam Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides an example of an app to classify phone SMS messages as either \"spam\" or \"ham\" (=not spam).  Some of this content has been adapted from a tutorial by Radimre Hurek:  https://radimrehurek.com/data_science_python/ and has been updated by Dr. Riley.  \n",
    "\n",
    "Please follow through this notebook linearly and insert your modifications and additions appropriately throughout.  You will also need to update some of the existing cells to conform to the style expectations of the checklist.  \n",
    "\n",
    "#### This Dataset is a dataset of over 5000 SMS phone messages and their spam or ham classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets start with importing some things..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [Errno -3] Temporary\n",
      "[nltk_data]     failure in name resolution>\n",
      "[nltk_data] Error loading averaged_perceptron_tagger: <urlopen error\n",
      "[nltk_data]     [Errno -3] Temporary failure in name resolution>\n",
      "[nltk_data] Error loading wordnet: <urlopen error [Errno -3] Temporary\n",
      "[nltk_data]     failure in name resolution>\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from textblob import TextBlob\n",
    "import pandas\n",
    "import sklearn\n",
    "import nltk\n",
    "import sys\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Load data, explore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the dataset and put it in the data folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains **a collection of more than 5 thousand SMS phone messages** (see the `readme` file for more info).  First, load them using Pandas with one column named `label` and one named `message`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = pandas.read_csv('/data/cs2300/L5/SMSSpamCollection.txt', sep='\\t', quoting=csv.QUOTE_NONE,\n",
    "                           names=[\"label\", \"message\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should take a look at the basic statistics for this dataset using Pandas describe() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>4827</td>\n",
       "      <td>4518</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>747</td>\n",
       "      <td>653</td>\n",
       "      <td>Please call our customer service representativ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      message                                                               \n",
       "        count unique                                                top freq\n",
       "label                                                                       \n",
       "ham      4827   4518                             Sorry, I'll call later   30\n",
       "spam      747    653  Please call our customer service representativ...    4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.groupby('label').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add a Pandas column that describes the length of the messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  length\n",
       "0   ham  Go until jurong point, crazy.. Available only ...     111\n",
       "1   ham                      Ok lar... Joking wif u oni...      29\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155\n",
       "3   ham  U dun say so early hor... U c already then say...      49\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...      61"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages['length'] = messages['message'].apply(len)\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will allow you to run the cell below to make a histogram of the length.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f04f7c67208>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages['length'].plot(bins=20, kind='hist', figsize=(15, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5574.000000\n",
       "mean       80.478292\n",
       "std        59.848302\n",
       "min         2.000000\n",
       "25%        36.000000\n",
       "50%        62.000000\n",
       "75%       122.000000\n",
       "max       910.000000\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.length.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find and print that really long one..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>ham</td>\n",
       "      <td>For me the love should start with attraction.i...</td>\n",
       "      <td>910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message  length\n",
       "1085   ham  For me the love should start with attraction.i...     910"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.loc[messages['length'] == 910]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see if there is there any difference in message length between spam and ham by running the following code to plot them side by side. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<matplotlib.axes._subplots.AxesSubplot object at 0x7f04f9ddc860>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x7f04f9ce3f28>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages.hist(column='length', by='label', bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, but this is not sufficient for us to create a classifier.  We need machine learning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we convert the raw messages (sequence of characters) into vectors (sequences of numbers).\n",
    "\n",
    "The mapping is not 1-to-1; we'll use the [bag-of-words](http://en.wikipedia.org/wiki/Bag-of-words_model) approach, where each unique word in a text will be represented by one number.\n",
    "\n",
    "As a first step, here is a function that will split a message into its individual words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_tokens(message):\n",
    "    return TextBlob(message).words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should tokenize them by applying the split_into_tokens method to the message column of the dataframe in the following cell.  Print the results to convince yourself that they are correct.  You do not need to store these results back in a column of the dataframe (i.e., you do not need to assign it back to a column).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Go, until, jurong, point, crazy, Available, o...\n",
       "1                       [Ok, lar, Joking, wif, u, oni]\n",
       "2    [Free, entry, in, 2, a, wkly, comp, to, win, F...\n",
       "3    [U, dun, say, so, early, hor, U, c, already, t...\n",
       "4    [Nah, I, do, n't, think, he, goes, to, usf, he...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = messages['message'].apply(split_into_tokens)\n",
    "tokens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With textblob, we can detect [part-of-speech (POS)](http://www.ling.upenn.edu/courses/Fall_2007/ling001/penn_treebank_pos.html) tags with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hello', 'NNP'),\n",
       " ('world', 'NN'),\n",
       " ('how', 'WRB'),\n",
       " ('is', 'VBZ'),\n",
       " ('it', 'PRP'),\n",
       " ('going', 'VBG')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(\"Hello world, how is it going?\").tags  # list of (word, POS) pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_lemmas(message):\n",
    "    words = TextBlob(message).words\n",
    "    # for each word, take its \"base form\" = lemma \n",
    "    return [word.lemma for word in words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize words into their base form ([lemmas](http://en.wikipedia.org/wiki/Lemmatisation)) by applying the split_into_lemmas function below to the message column of the dataframe. The base lemma takes plural nouns and makes them singular - if you want to do more sophisticated lemmatization (e.g., removing verb tenses), call .lemmatize() and pass in the part of speech. Again, you do not need to store these results back in a column of the DataFrame, so you can use `.head()` to view the output.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Go, until, jurong, point, crazy, Available, o...\n",
       "1                       [Ok, lar, Joking, wif, u, oni]\n",
       "2    [Free, entry, in, 2, a, wkly, comp, to, win, F...\n",
       "3    [U, dun, say, so, early, hor, U, c, already, t...\n",
       "4    [Nah, I, do, n't, think, he, go, to, usf, he, ...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = messages['message'].apply(split_into_lemmas)\n",
    "tokens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can probably think of many more ways to improve the preprocessing: decoding HTML entities (those `&amp;` and `&lt;` we saw above); filtering out stop words (pronouns etc); adding more features, such as an word-in-all-caps indicator and so on.  So keep those in mind for later..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Data to vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now need to convert each message, represented as a list of tokens (lemmas) above, into a vector that machine learning models can understand.\n",
    "\n",
    "Doing that requires essentially three steps in the bag-of-words model:\n",
    "\n",
    "1. counting how many times does a word occur in each message (term frequency)\n",
    "2. weighting the counts, so that frequent tokens get lower weight (inverse document frequency)\n",
    "3. normalizing the vectors to unit length, to abstract from the original text length\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each vector has as many dimensions as there are unique words in the SMS corpus.  We can count the number of unique words using the following cell..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11012\n"
     ]
    }
   ],
   "source": [
    "bow_transformer = CountVectorizer(analyzer=split_into_lemmas).fit(messages['message'])\n",
    "print(len(bow_transformer.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we used `scikit-learn` (`sklearn`), a powerful Python library for teaching machine learning. It contains a multitude of various methods and options.\n",
    "\n",
    "Let's take one text message and get its bag-of-words counts as a vector, putting to use our new `bow_transformer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U dun say so early hor... U c already then say...\n"
     ]
    }
   ],
   "source": [
    "message4 = messages['message'][3]\n",
    "print(message4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 4191)\t2\n",
      "  (0, 4764)\t1\n",
      "  (0, 5365)\t1\n",
      "  (0, 6221)\t1\n",
      "  (0, 6245)\t1\n",
      "  (0, 7139)\t1\n",
      "  (0, 9282)\t2\n",
      "  (0, 9591)\t1\n",
      "  (0, 10056)\t1\n",
      "(1, 11012)\n"
     ]
    }
   ],
   "source": [
    "bow4 = bow_transformer.transform([message4])\n",
    "print(bow4)\n",
    "print(bow4.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, nine unique words are in this message.  Two of them appear twice, the rest only once. \n",
    "\n",
    "Write some code in the next cell that identifies the words that appear twice.  You are encouraged to use the CountVectorizer's get_feature_names() method to make this easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words that were used twice: U, say\n"
     ]
    }
   ],
   "source": [
    "feature_name_1 = bow_transformer.get_feature_names()[4191]\n",
    "feature_name_2 = bow_transformer.get_feature_names()[9282]\n",
    "print(f'Words that were used twice: {feature_name_1}, {feature_name_2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bag-of-words counts for the entire SMS corpus are a large, sparse matrix (generated using `bow_transformer.transform()` on the appropriate dataframe column).  In the following cell, calculate the sparsity using `.nnz` and the shape.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Non-Zero Elements: 81621\n",
      "Shape of messages_bow: (5574, 11012)\n",
      "Sparsity: 99.867025384188 %\n"
     ]
    }
   ],
   "source": [
    "messages_bow = bow_transformer.transform(messages['message'])\n",
    "print(f'Number of Non-Zero Elements: {messages_bow.nnz}')\n",
    "print(f'Shape of messages_bow: {messages_bow.shape}')\n",
    "print(f'Sparsity: {(1 - (messages_bow.nnz / (messages_bow.shape[0] * messages_bow.shape[1]))) * 100} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this markdown cell, hypothsize why the sparsity is non-zero:**\n",
    "Because there are messages that have words in it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, lets see what the bow array looks like if we convert it to a \"dense\" array and print it out.  Lots of 0s right?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_array = messages_bow.toarray()\n",
    "print(messages_array)\n",
    "type(messages_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should next calculate the storage required by both the sparse representation and the full array by using `numpy_array.data.nbytes` to find its size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense Array Storage size: 491047104\n",
      "Bag of Words representation storage size: 652968\n"
     ]
    }
   ],
   "source": [
    "print(f'Dense Array Storage size: {messages_array.data.nbytes}')\n",
    "print(f'Bag of Words representation storage size: {messages_bow.data.nbytes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Term weighting and normalization can be done with [TF-IDF](http://en.wikipedia.org/wiki/Tf%E2%80%93idf), using scikit-learn's `TfidfTransformer`, and we can apply it to the message we used above.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 10056)\t0.22510385070095637\n",
      "  (0, 9591)\t0.1955442748962185\n",
      "  (0, 9282)\t0.49597495370832545\n",
      "  (0, 7139)\t0.4269339327922034\n",
      "  (0, 6245)\t0.3100112284407115\n",
      "  (0, 6221)\t0.2913528957227454\n",
      "  (0, 5365)\t0.2860779240943588\n",
      "  (0, 4764)\t0.25892595706356525\n",
      "  (0, 4191)\t0.391088549792437\n"
     ]
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer().fit(messages_bow)\n",
    "tfidf4 = tfidf_transformer.transform(bow4)\n",
    "print(tfidf4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To transform the entire bag-of-words corpus into TF-IDF corpus at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5574, 11012)\n",
      "  (0, 10754)\t0.21213229601299222\n",
      "  (0, 10579)\t0.18167554410946474\n",
      "  (0, 10384)\t0.21213229601299222\n",
      "  (0, 10061)\t0.14837206960284824\n",
      "  (0, 8703)\t0.20860154971594694\n",
      "  (0, 8407)\t0.15067087432963316\n",
      "  (0, 8163)\t0.16242573626983609\n",
      "  (0, 7587)\t0.25289503583337986\n",
      "  (0, 7478)\t0.2993512784929627\n",
      "  (0, 7268)\t0.1008229769857705\n",
      "  (0, 6902)\t0.1757328869964933\n",
      "  (0, 6874)\t0.14339196897060574\n",
      "  (0, 6235)\t0.1811790743555944\n",
      "  (0, 5825)\t0.23930745589325064\n",
      "  (0, 5324)\t0.25736981907741296\n",
      "  (0, 5323)\t0.28576369855283346\n",
      "  (0, 4792)\t0.2993512784929627\n",
      "  (0, 2158)\t0.23182967104573837\n",
      "  (0, 1562)\t0.2993512784929627\n",
      "  (0, 1176)\t0.2761231571631713\n",
      "  (1, 10675)\t0.4010902457332356\n",
      "  (1, 10321)\t0.20081724764839\n",
      "  (1, 8404)\t0.5049322644944293\n",
      "  (1, 7616)\t0.3771878029805894\n",
      "  (1, 3173)\t0.2915507170181676\n",
      "  :\t:\n",
      "  (5572, 7329)\t0.2752494318008217\n",
      "  (5572, 7268)\t0.10973512009181839\n",
      "  (5572, 7206)\t0.11082395540202505\n",
      "  (5572, 7018)\t0.1735585546845164\n",
      "  (5572, 6945)\t0.2011564437133181\n",
      "  (5572, 6780)\t0.2636343815503537\n",
      "  (5572, 6688)\t0.179984655695234\n",
      "  (5572, 6644)\t0.11901300463294123\n",
      "  (5572, 6299)\t0.23369053277378316\n",
      "  (5572, 6042)\t0.18312783843890487\n",
      "  (5572, 5355)\t0.270953498846931\n",
      "  (5572, 5349)\t0.14544421749367942\n",
      "  (5572, 5175)\t0.3258121261357\n",
      "  (5572, 5084)\t0.13849274157992586\n",
      "  (5572, 4802)\t0.11179120288670394\n",
      "  (5572, 4652)\t0.31102348607503505\n",
      "  (5572, 4086)\t0.1857747292164984\n",
      "  (5572, 2390)\t0.08462483717048569\n",
      "  (5572, 18)\t0.2295570645615035\n",
      "  (5573, 10276)\t0.47604967083628325\n",
      "  (5573, 10155)\t0.1584262474010421\n",
      "  (5573, 8178)\t0.42481378910273787\n",
      "  (5573, 7379)\t0.2294761603772292\n",
      "  (5573, 3551)\t0.607560694420571\n",
      "  (5573, 2496)\t0.38212795505299313\n"
     ]
    }
   ],
   "source": [
    "messages_tfidf = tfidf_transformer.transform(messages_bow)\n",
    "print(messages_tfidf.shape)\n",
    "print(messages_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Training a model, detecting spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With messages represented as vectors, we can finally train our spam/ham classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using scikit-learn here, choosing the [Naive Bayes](http://en.wikipedia.org/wiki/Naive_Bayes_classifier) classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_detector = MultinomialNB().fit(messages_tfidf, messages['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try classifying our single random message:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: ham\n",
      "expected: ham\n"
     ]
    }
   ],
   "source": [
    "print('predicted:', spam_detector.predict(tfidf4)[0])\n",
    "print('expected:', messages.label[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hooray!\n",
    "\n",
    "A natural question is to ask, how many messages do we classify correctly overall?  The following cell will calculate this for us..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9721923214926445\n"
     ]
    }
   ],
   "source": [
    "all_predictions = spam_detector.predict(messages_tfidf)\n",
    "print('accuracy', accuracy_score(messages['label'], all_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are quite a few possible metrics for evaluating model performance. Which one is the most suitable depends on the task. For example, the cost of mispredicting \"spam\" as \"ham\" is probably much lower than mispredicting \"ham\" as \"spam\".  Differences between errors can be illuminated using metrics other than accuracy, so in the following cell, and in the cells below, you should use sklearn to calculate recall and precision in addition to accuracy.  Please include statements about what you can interpret from these results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Let's get realistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above \"evaluation\", we committed a cardinal sin. For simplicity of demonstration, we evaluated accuracy on the same data we used for training. **Never evaluate on the same dataset you train on!**\n",
    "\n",
    "Such evaluation tells us nothing about the true predictive power of our model. If we simply remembered each example during training, the accuracy on training data would trivially be 100%, even though we wouldn't be able to classify any new messages.  This is exactly like memorizing the exact answers for an exam without understanding the underlying material!\n",
    "\n",
    "A proper way is to split the data into a training/test set, where the model only ever sees the **training data** during its model fitting and parameter tuning. The **test data** is never used in any way -- thanks to this process, we make sure we are not \"cheating\", and that our final evaluation on test data is representative of true predictive performance.\n",
    "\n",
    "The following code splits the dataset into a training and testing set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4459 1115 5574\n"
     ]
    }
   ],
   "source": [
    "msg_train, msg_test, label_train, label_test = \\\n",
    "    train_test_split(messages['message'], messages['label'], test_size=0.2)\n",
    "\n",
    "print(len(msg_train), len(msg_test), len(msg_train) + len(msg_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, as requested, the test size is 20% of the entire dataset.\n",
    "\n",
    "Next, lets set up our split datasets to be ready to be used by the Bayes model for training and prediction..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_messages_bow = bow_transformer.transform(msg_train)\n",
    "train_tfidf_transformer = TfidfTransformer().fit(train_messages_bow)\n",
    "train_messages_tfidf = train_tfidf_transformer.transform(train_messages_bow)\n",
    "test_messages_bow = bow_transformer.transform(msg_test)\n",
    "test_tfidf_transformer = TfidfTransformer().fit(test_messages_bow)\n",
    "test_messages_tfidf = test_tfidf_transformer.transform(test_messages_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can train a new Naive Bayes classifier with only the training data, and test it with the test data, and our accuracy should drop.  In this cell answer: why?  \n",
    "\n",
    "#### The reason why the accuracy is lower tha what it was previously, is because the training set isn't the test set. Since we split up our data into a test set and a training set, the model cannot simply memorize what it did earlier and predict the exact same outcome again, because it has already seen the data. The way we have it set up now we are seeing its true predictive power and seeing exactly how useful it would be in actually predicting spam or ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated accuracy 0.9542600896860987\n"
     ]
    }
   ],
   "source": [
    "split_spam_detector = MultinomialNB().fit(train_messages_tfidf, label_train)\n",
    "test_predictions = split_spam_detector.predict(test_messages_tfidf)\n",
    "print('updated accuracy', accuracy_score(label_test, test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, re-run this experiment changing the test size to a different value (in the subsequent cells of this part) and develop an explanation for the results (it should be different than your accuracy value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated accuracy 0.9569635385534967\n"
     ]
    }
   ],
   "source": [
    "msg_train, msg_test, label_train, label_test = \\\n",
    "    train_test_split(messages['message'], messages['label'], test_size=0.3)\n",
    "train_messages_bow = bow_transformer.transform(msg_train)\n",
    "train_tfidf_transformer = TfidfTransformer().fit(train_messages_bow)\n",
    "train_messages_tfidf = train_tfidf_transformer.transform(train_messages_bow)\n",
    "test_messages_bow = bow_transformer.transform(msg_test)\n",
    "test_tfidf_transformer = TfidfTransformer().fit(test_messages_bow)\n",
    "test_messages_tfidf = test_tfidf_transformer.transform(test_messages_bow)\n",
    "\n",
    "split_spam_detector = MultinomialNB().fit(train_messages_tfidf, label_train)\n",
    "test_predictions = split_spam_detector.predict(test_messages_tfidf)\n",
    "print('updated accuracy', accuracy_score(label_test, test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Next Steps\n",
    "\n",
    "In the following cells you should make some changes to the dataset (cast to lowercase, remove numbers, remove non-words, add content, lemmatize verbs using .lemmatize(\"v\"), etc) to sufficiently change the sparsity percentage.  The number of columns in your bag of words model should change significantly. **After making your changes to the data set, repeat the size evaluation done in part 3.** The goal of this is see the size comparison in the non-compressed version of the matrix (`toarray`) vs the sparse representation as the size of the data changes.  If we didn't have a sparse representation, our ability to use a BOW model would be very limiting...  Argue how using sparse matrices can enable more powerful data analyses.  \n",
    "\n",
    "Next, rerun the experiments from part 5 to assess the accuracy of your new dataset and compare it with your previous results.  You should make arguments about what caused the changes and why they make sense. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reloading new spam messages dataframe, because I am paranoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = pandas.read_csv('/data/cs2300/L5/SMSSpamCollection.txt', sep='\\t', quoting=csv.QUOTE_NONE,\n",
    "                           names=[\"label\", \"message\"])\n",
    "\n",
    "messages['length'] = messages['message'].apply(len)\n",
    "pandas.set_option('display.max_rows', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making tokens that don't have punctuation, upper case letters or numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry in  a wkly comp to win fa cup final...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>freemsg hey there darling its been  weeks now ...</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>even my brother is not like to speak with me t...</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>as per your request melle melle oru minnaminun...</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>winner as a valued network customer you have b...</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>had your mobile  months or more u r entitled t...</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  length\n",
       "0   ham  go until jurong point crazy available only in ...     111\n",
       "1   ham                            ok lar joking wif u oni      29\n",
       "2  spam  free entry in  a wkly comp to win fa cup final...     155\n",
       "3   ham        u dun say so early hor u c already then say      49\n",
       "4   ham  nah i dont think he goes to usf he lives aroun...      61\n",
       "5  spam  freemsg hey there darling its been  weeks now ...     147\n",
       "6   ham  even my brother is not like to speak with me t...      77\n",
       "7   ham  as per your request melle melle oru minnaminun...     160\n",
       "8  spam  winner as a valued network customer you have b...     157\n",
       "9  spam  had your mobile  months or more u r entitled t...     154"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages['message'] = messages['message'].str.replace(r'[^a-zA-Z0-9 ]', '').str.lower().str.replace('\\d+', '')\n",
    "messages['message'] = messages['message']\n",
    "messages.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOW model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8077\n"
     ]
    }
   ],
   "source": [
    "bow_transformer = CountVectorizer(analyzer=split_into_lemmas).fit(messages['message'])\n",
    "print(len(bow_transformer.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The number of unique words has decreased by 3000. It went from 11012 to 8077. A 27 % decrease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating BOW model sparsity of new messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Non-Zero Elements: 75540\n",
      "Shape of messages_bow: (5574, 8077)\n",
      "Sparsity: 99.83221237249174 %\n"
     ]
    }
   ],
   "source": [
    "messages_bow = bow_transformer.transform(messages['message'])\n",
    "print(f'Number of Non-Zero Elements: {messages_bow.nnz}')\n",
    "print(f'Shape of messages_bow: {messages_bow.shape}')\n",
    "print(f'Sparsity: {(1 - (messages_bow.nnz / (messages_bow.shape[0] * messages_bow.shape[1]))) * 100} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing BOW model to an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_array = messages_bow.toarray()\n",
    "print(messages_array)\n",
    "type(messages_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating size of each representation and comparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense Array Storage size: 360169584\n",
      "Bag of Words representation storage size: 604320\n",
      "Ratio of Dense Array Storage size / Bag of Words Representation: 595.9915011914218\n"
     ]
    }
   ],
   "source": [
    "print(f'Dense Array Storage size: {messages_array.data.nbytes}')\n",
    "print(f'Bag of Words representation storage size: {messages_bow.data.nbytes}')\n",
    "print(f'Ratio of Dense Array Storage size / Bag of Words Representation: {360169584 / 604320}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Size Conclusion: In both versions of messages, the suggested changes and the one with my changes have a big size disparity between the two. The array version is almost 600 times larger than the BOW model. This has a huge impact on performance as well as being able to compute intensive data analysis. Without a BOW model, some large data sets would simply be to large for analysis or would need many computers to run, whereas the BOW model can condense it down and make the information more pallatable for any kind of computer. \n",
    "\n",
    "#### Another thing to note, is that if we had a large data set in a dense array format and we didn't have the option of converting to a sparse matrix, many would be tempted to change the data and make edits to it, like removing all the numbers from tokens or other changes like that in efforts to reduce the size. Unfortunately, this could have unwanted side effects, in the case where we may be removing to much.\n",
    "\n",
    "#### Comparing the previous Array and BOW model to the dense array and BOW model I made, the size decreased by about 27% in the dense array model and about 8% in the BOW model. This makes sense because, the BOW model only stores one of each and not all the occurences of it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7334725753723211\n",
      "0.9254971147131253\n"
     ]
    }
   ],
   "source": [
    "print(360169584 / 491047104)\n",
    "\n",
    "#652968\n",
    "print(604320 /652968 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4459 1115 5574\n"
     ]
    }
   ],
   "source": [
    "msg_train, msg_test, label_train, label_test = \\\n",
    "    train_test_split(messages['message'], messages['label'], test_size=0.2)\n",
    "\n",
    "print(len(msg_train), len(msg_test), len(msg_train) + len(msg_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_messages_bow = bow_transformer.transform(msg_train)\n",
    "train_tfidf_transformer = TfidfTransformer().fit(train_messages_bow)\n",
    "train_messages_tfidf = train_tfidf_transformer.transform(train_messages_bow)\n",
    "test_messages_bow = bow_transformer.transform(msg_test)\n",
    "test_tfidf_transformer = TfidfTransformer().fit(test_messages_bow)\n",
    "test_messages_tfidf = test_tfidf_transformer.transform(test_messages_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated accuracy 0.957847533632287\n"
     ]
    }
   ],
   "source": [
    "split_spam_detector = MultinomialNB().fit(train_messages_tfidf, label_train)\n",
    "test_predictions = split_spam_detector.predict(test_messages_tfidf)\n",
    "print('updated accuracy', accuracy_score(label_test, test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next, rerun the experiments from part 5 to assess the accuracy of your new dataset and compare it with your previous results. You should make arguments about what caused the changes and why they make sense.\n",
    "\n",
    "### The accuracy of the model didn't really change much overall. It seems like numbers, punctuation and Upper case letters don't really mean much to spam. Either way the model predicts around 95% to 96% depending on which part of the data set it chooses to train and test on. It is quite interesting that despite the number of unique words decreased by 27% the model was still able to predict at almost the same rate. The model was able to produce similar results despite having less data to work on which is a win in my book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "### End of notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
